# 该论文介绍

在该文中，介绍了**automatically mining trivia for entities from unstructured text**，提出了使用**“Wikipedia Trivia Miner(WTM)”**方法去挖掘trivia for entities。尽管interesting是一个主观概念，可能对于每个人来说都不太一样，但是有一些关于interesting的事实是大多数人都很赞同的。

该文章选择了Wikipedia作为知识源，因为它的事实正确性是trivia的一个重要属性。对于给定的实体，WTM从Wikipedia中提取它的相关句子，并且基于它的interesting使用机器学习模型进行排序。最终模型的输出是含有k个句子的列表，这是关于该实体最有趣的k个句子。

# 该文章的相关工作

更早的trivia mining是关注从结构化数据库中生成问题。然而，工作局限于目标领域中结构化数据库的可用性，并且仅限于发现可以表示为结构化查询的trivia。

最近的文本挖掘领域的趋势是从无结构的文本中挖掘interesting。[Gamon et al., 2014]使用了anchors来定义interesting（在wikipedia上），将interesting mining的问题转化为链接的点击预测任务，但是这个方法有一个限制，对于没有anchors的文本就没有办法进行interesting mining。

[Ganguly et al., 2014]从审美学的的基础上视图找出漂亮的句子，作者定义了许多的特征，然而对于trivia mining，除了POS而言，其他的特征都是没用的。

trivia mining也可以使用标准异常检测或者是异常值检测技术来做。但是这样做的话需要对该领域有一定的背景知识，但是这种背景知识我们不总是可以获得的。这个方法还假设输入的知识存在与结构化格式（XML）中。但是对所有的实体的fact而言，丰富的结构化数据不都是可获得的。**因此本文采用了无结构文本作为trivia mining的源。**

# Wikipedia Trivia Miner方法

WTM方法由三个模块组成：Filtering&Grading模块，Candidate Selection模块，Interestingness Ranker模块。

在该方法中最为重要的是Interestingness Ranker模块。

本文所使用的训练集的域是：movie域

需要注意的是：对于任意给定的电影实体，它的Wikipedia主页上包含目标实体的不同的方面，使用了超过一个邻接的句子。但是，在不需要合适的上下文的情况下，不是所有的句子都是可以独立理解的。

## Filtering & Grading模块

这个模块要做的是准备用于训练分类器（分为5类，very interesting，interesting，ambiguous，boring，very boring）的训练数据集。

具体做法：

1、首先从Mocrosoft's internal Knowledge Graph中选取最受欢迎的5000个电影实体。

2、从IMDB中抓取关于这些实体的trivia。（得到了trivia和它们的interesting vote data）

3、计算Likeness Ratio(LR)。（因为如果投票数据较少，可能导致该投票不可靠，因此本文当vote超过100的时候，该实体才会被使用）

4、最终根据所得的LR分数来进行等级划分。90分以上=very interesting，90-75=interesting，75-25=ambiguous，25-10=boring，10以下=very boring。

## Candidate Selection模块

这个模块要做的是从实体的wikipedia中提取需要进行interesting判断的句子。

具体做法：

1、从目标实体的wikipedia中提取含在paragraph HTML元素中的句子。（包含在其他元素中的句子不要）将得到的结果称为core content text（CCT），之后的步骤的处理都是在CCT集合中。

2、将需要上下文才能理解的句子去除，具体做法：

​	2.1、对于目标实体的句子（即是目标实体包含在CCT中的句子），使用Sentence Detector来辨别独立的句子。

​	2.2、使用Co-Reference Resolution来找出所给的句子的关系，然后删除那些在当前句子之外提到的句子，但是包含目标实体的句子被保留。

最后得到的CCT集合即是我们进行trivia挖掘的数据集。

## Interestingness Ranker模块(IR)

该模块要做的是使用Filtering & Grading模块得到的训练集训练出一个SVM分类器（**Rank SVM [Joachims, 2006] based formulation**），将candidate sentences中生成的CCT数据集中的句子以有趣程度递减的顺序进行排序。使用这样的方法允许了WTM能够适应新的领域，仅仅需要改变训练集即可。	

具体做法：

1、使用特征提取器，将训练集的（Movie，trivia，grade）三元组变成（movie，features，grade），即是将每个trivia变成一个特征向量。

​	所使用的特征分为三类：Unigram，Linguistic，Entity

​	1.1、Unigram：首先做预处理：大小写转换，stemming，stop word removal，移除标点符号。之后使用TF-IDF来作为每个词的大小作为特征。

​	1.2、Linguistic：（Unigram不足以抓住句子的语义，因此使用Linguistic feature）

​		1.2.1、词的最高级：使用一个二进制数来表示该句子是否含有词的最高级。

​		1.2.2、转折词：使用一个二进制数来表示该句子是否含有转折词。

​		1.2.3、句子的根词：将所有的根词做成一个向量，如果该句子出现了该词，则向量的该词所			在的位置为1，否则为0。

​		1.2.4、句子的主体：与根词的做法类似。

​		1.2.5、可阅读性分数：复杂的和长的trivia很难有趣，因此使用Fog Index作为特征。（该特征定义了可阅读性[Gunning, 1969]）

​	1.3、Entity：（为了学习实体和属性级别的泛化，因而使用了命名实体[Manning et al., 2014]和entity-linking特性）

2、使用特征和grade来训练Rank SVM模型，使用NDCG@10[Jarvelin ¨and Kekal¨ ainen, 2002 ¨ ]来评价排序性能最好的10个排序。

3、在测试阶段使用从candidate sentences中生成的CCT集合，利用训练好的Rank SVM来计算一个分数，并将其根据分数从高到低进行排序。

# 实验设置

SVM：使用线性核函数，C=17，e=0.21。

## 创建测试集

为了评估系统的有效性，从IMDB中最受欢迎的5000部电影中随机选取了20部电影的维基百科主页，如同之前一样提取CCT集合。

然后采用人工标注的方法，根据一个定义好的准则，使用5个人对sentence进行标注（interesting或者boring），对每个句子采用投票的原则（对某个句子，两个人标注为interesting，三个人标注为boring，那么该句子的最终标签为boring）。

因为interestingness是一个主观概念，尽可能多的裁判进行标注可能得到更加理想的结果。但是，本文选择5个人进行标注是有一定原因的。该文章说明了，五种判断虽然不理想，但足以充分反映群众的普遍智慧。

## 评估方法

1、采用Precision@k作为评估方法。

2、为了证明WTM的有效性，能够带来各种各样的trivia，同样使用Recall@k作为评估方法。

3、采用了NDCG@k作为评估方法。

# 基准方法

该文章定义了两种基准方法。

1、“random”：（该方法改变了提取候选句子的方法，并且重新定义了interestingness。）随机从目标实体的维基百科上选取句子。句子中含有词的最高级则定义为interestingness。

2、SuperPOS：（该方法仅仅改变了interestingness的定义方法）使用candidate selection集合中的句子，根据它其中含有最高级词的个数进行排序。（**不太清楚它对有相同最高级词个数的句子是如何处理的。**）

