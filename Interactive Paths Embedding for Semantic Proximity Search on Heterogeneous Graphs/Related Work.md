# Related Work

对于语义相似搜索，更早的工作例如Personalized PageRank通过随机寻找，测量查询节点到目标节点的相似度。但是它仅仅考虑了同构图。

Supervised Random Walk可以被应用在异构图中。

MPP和PRA计算两个对象之间特定路径模式的实例，以度量它们的接近程度。

PRep考虑从概率的角度考虑基于路径的相关性。

**通常，图形嵌入的重点是为每个节点生成一个低维度的矢量。[3]**

例如DeepWalk，node2vec，metapath2vec，struct2vec，GraphSAGE，EP以及更多[4,6,21,23,26,27,40]。

为了使用**节点嵌入**进行语义接近搜索，一个方法是连接两个节点嵌入向量，将输出映射成一个相似度分数。

**ProxEmbed展示了一些方法是间接地，它直接将两个节点之间的每个连接路径嵌入到一个向量中，并为接近分数聚合多个路径。**

尽管基于路径的方法对于在两个可能的远程节点之间进行建模是很自然的，但是以上的方法趋于对路径的**弱耦合**建模。

**一些先驱工作已经探索了路径的相互依赖。例如Word-to-Word Attention LSTM [30] and Coupled-LSTM[20], DF-LSTM [19]。**

但是，这些方法被设计用来一次处理两个路径。在我们的任务中，我们有许多的交互路径。如果将方法用在每两个可能的路径上，我们仍然限制了我们在每次嵌入仅仅能看见两条路径。从另一方面来看，如果我们选择直接扩展他们的方法到多条路径上，我们可能high generalization complexity。（以下是说明直接扩展他们的方法的坏处）

由于单路径具有有限的表达能力，最近的一些工作还利用了更高阶的子图结构来进行语义接近搜索。例如，**Meta-graph Proximity（MGP）**首先将频繁的子图模式挖掘为元图，然后它计算两个物体之间的特定元图的实例来测量它们的接近度。尽管元图是强大的，但是频繁的子图挖掘是具有挑战性的。[38]在实践中，元图的大小是很小的，这也限制了性能。

一些其他的工作考虑了embedding with tree或者directed acyclic graphs。它们不是为了路径嵌入所设计的，而且通常它们都无法适用于我们的工作，因为它们的高度定制的设计。

最后值得一提的是一些相关但是不同的概念。

Grid-LSTM和Multidimensional-RNN是为了多维数据所设计的，而不是多路径。

Graph kernels通过子图来测量图之间的相关相似度，但是它们不是为了嵌入多路径设计的。

Knowledge graph嵌入，例如TransE，TransH，ProjE和TransNet，考虑异构图的特殊类型。知识图包含(entity, relation, entity) 三元组。知识图的一个典型的目的是学习实体和关系的嵌入，例如对于每个三元组，添加头部实体的嵌入和关联的嵌入在某种程度上等于尾部实体的嵌入。一些三元组事实没有存在于我们的数据中，因此我们不能应用知识图词嵌入。

